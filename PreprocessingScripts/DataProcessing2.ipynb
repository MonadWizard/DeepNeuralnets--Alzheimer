{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Stage-2 [Preparing Tefla ready data]\n",
    "\n",
    "This Notebook runs after the DataProcessing-1.ipynb notebook. This notebook creates the csv file with consists of nii files name and its corresponding label. Then it prepares the data in the tefla ready format, which the adequate distribution of data between training, validation, and test for all the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Alzheimer\", \"MCI\", \"Normal\"]\n",
    "#sourceDir = '/home/nagdev/work/siddhant/data/data/'\n",
    "#sourceDir = '/home/h_hack/work/pywork/ML/datasets/Alzheimer_detect/fsl_preprocessed/images/'\n",
    "#path_tocsvfile = '/home/h_hack/work/pywork/ML/datasets/Alzheimer_detect/fsl_preprocessed/'\n",
    "#path_tocsvfile = '/home/nagdev/work/siddhant/data/raw/'\n",
    "#sourceDir = '/home/ec2-user/final_data/images/'\n",
    "#path_tocsvfile = '/home/ec2-user/final_data/'\n",
    "sourceDir = '/home/ubuntu/Select_data/images/'\n",
    "path_tocsvfile = '/home/ubuntu/Select_data/'\n",
    "\n",
    "# 0 represents Alzheimer class, 1 represents MCI class, 2 represents Normal class.\n",
    "count = 0\n",
    "with open(path_tocsvfile + 'all.csv','a') as o:\n",
    "    o.write('nii' + ',' + 'label' +'\\n')\n",
    "    for class_ in classes:\n",
    "        images_path = os.path.join(os.path.join(sourceDir,class_), '*.nii')\n",
    "        print 'Working on: ', images_path\n",
    "        for file_ in glob.glob(images_path):\n",
    "            o.write(file_ + ',' + str(count) +'\\n')\n",
    "        count += 1\n",
    "        print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# script to create a tefla compatible data dir for training and validation data\n",
    "#sourceDir = '/home/nagdev/work/siddhant/data/raw/'\n",
    "#destDir = '/home/nagdev/work/siddhant/data/raw/processed/'\n",
    "#sourceDir = '/home/ec2-user/final_data/'\n",
    "#destDir = '/home/ec2-user/final_data/processed/'\n",
    "sourceDir = '/home/ubuntu/Select_data/'\n",
    "destDir = '/home/ubuntu/Select_data/processed/'\n",
    "\n",
    "categories_picked_for_validation_data = [0,1]\n",
    "#categories_picked_for_validation_data = [0,1,2] # if we use all three categories alzheimer, mci and normal\n",
    "validation_data_percentage = 10\n",
    "\n",
    "def create_tefla_data(source_dir,destination_dir,validation_categories,validation_percentage):\n",
    "    #if os.path.exists(destination_dir):\n",
    "    #    shutil.rmtree(destination_dir)\n",
    "\n",
    "    training_dir = destination_dir + 'training_64/'\n",
    "    validation_dir = destination_dir + 'validation_64/'\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(training_dir)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.makedirs(validation_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    labels = pd.read_csv( source_dir + 'all.csv')\n",
    "    validation_dict = {}\n",
    "\n",
    "    for c in validation_categories:\n",
    "        validation_dict[c] = []\n",
    "    # now test_set has some nii files inside it from each class\n",
    "\n",
    "    #validation set creation\n",
    "    validation_set = []\n",
    "\n",
    "    for i, rows in labels.iterrows():\n",
    "        if validation_dict.has_key(rows['label']):\n",
    "            validation_dict[rows['label']].append(rows['nii'])\n",
    "\n",
    "    for l in validation_dict:\n",
    "        np.random.seed(0)\n",
    "        n = math.ceil(validation_percentage * len(validation_dict[l]) / 100.0)\n",
    "        random_array = np.random.choice(validation_dict[l],int(n))\n",
    "        validation_set = validation_set + random_array.tolist()\n",
    "    # add some of the nii files to validation set which are not part of test set.\n",
    "\n",
    "    training_images = []\n",
    "    training_labels = []\n",
    "    validation_images = []\n",
    "    validation_labels =[]\n",
    "    count = 0\n",
    "    for i, rows in labels.iterrows():\n",
    "        if rows['nii'] in validation_set:\n",
    "            #print rows['nii']\n",
    "            for file_ in glob.glob(os.path.join(rows['nii'], '*.jpg')):\n",
    "                validation_images.append(os.path.basename(file_).replace('.jpg', ''))\n",
    "                validation_labels.append(rows['label'])\n",
    "                count = count + 1\n",
    "                process_and_save_image(file_, validation_dir + os.path.basename(file_).replace('.jpg','') + \".jpg\")\n",
    "        else:\n",
    "            #print rows['nii']\n",
    "            for file_ in glob.glob(os.path.join(rows['nii'], '*.jpg')):\n",
    "                count = count + 1\n",
    "                training_images.append(os.path.basename(file_).replace('.jpg', ''))\n",
    "                training_labels.append(rows['label'])\n",
    "                process_and_save_image(file_, training_dir + os.path.basename(file_).replace('.jpg','') + \".jpg\")\n",
    "        sys.stdout.write(\"\\r\" + str(count))\n",
    "                \n",
    "    header = ['image', 'label']\n",
    "\n",
    "    # saving training csv\n",
    "    training_out = np.column_stack((training_images, training_labels))\n",
    "    training_out = np.row_stack((header, training_out))\n",
    "    np.savetxt(destination_dir + 'training_labels.csv', training_out, delimiter=',', fmt='%s')\n",
    "\n",
    "    # saving validation csv\n",
    "    validation_out = np.column_stack((validation_images, validation_labels))\n",
    "    validation_out = np.row_stack((header, validation_out))\n",
    "    np.savetxt(destination_dir + 'validation_labels.csv', validation_out, delimiter=',', fmt='%s')\n",
    "\n",
    "def process_and_save_image(source_path,destination_path):\n",
    "    img = resize(source_path, 64)\n",
    "    img.save(destination_path, quality=100)\n",
    "\n",
    "def resize(fname, target_size):\n",
    "    # print('Processing image: %s' % fname)\n",
    "    img = Image.open(fname)\n",
    "    return img\n",
    "\n",
    "#calling method\n",
    "create_tefla_data(sourceDir,destDir,categories_picked_for_validation_data,validation_data_percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
