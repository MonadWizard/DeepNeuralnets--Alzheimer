{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Stage-2 [Preparing Tefla ready data]\n",
    "\n",
    "This Notebook runs after the DataProcessing-1.ipynb notebook. This notebook creates the csv file with consists of image name and its corresponding label. Then it prepares the data in the tefla ready format, which the adequate distribution of data between training, validation, and test for all the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alzheimer\n",
      "/home/nagdev/work/siddhant/data/raw/Alzheimer\n",
      "1\n",
      "MCI\n",
      "/home/nagdev/work/siddhant/data/raw/MCI\n",
      "2\n",
      "Normal\n",
      "/home/nagdev/work/siddhant/data/raw/Normal\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import shutil\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = [\"Alzheimer\", \"MCI\", \"Normal\"]\n",
    "sourceDir = '/home/nagdev/work/siddhant/data/raw/'\n",
    "\n",
    "# 0 represents Alzheimer class, 1 represents MCI class, 2 represents Normal class.\n",
    "count = 0\n",
    "for class_ in classes:\n",
    "    print class_\n",
    "    for root,dir,files in os.walk(os.path.join(sourceDir,class_)):\n",
    "        print os.path.join(sourceDir,class_)\n",
    "        with open(sourceDir + 'all.csv','a') as o:\n",
    "            for f in files:\n",
    "                o.write(f + ',' + str(count) +'\\n')\n",
    "    count += 1\n",
    "    print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             image  label\n",
      "0   Alzheimer61_12      0\n",
      "1    Alzheimer5_42      0\n",
      "2    Alzheimer72_1      0\n",
      "3   Alzheimer17_11      0\n",
      "4  Alzheimer129_39      0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import shutil\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# script to create a tefla compatible data dir for training and validation data\n",
    "sourceDir = '/home/nagdev/work/siddhant/data/raw/'\n",
    "destDir = '/home/nagdev/work/siddhant/data/raw/processed/'\n",
    "categories_picked_for_validation_data = [0,1,2]\n",
    "categories_picked_for_test_data = [0,1,2]\n",
    "validation_data_percentage = 10\n",
    "test_data_percentage = 20\n",
    "\n",
    "def create_tefla_data(source_dir,destination_dir,validation_categories,test_categories,validation_percentage,test_percentage):\n",
    "    #if os.path.exists(destination_dir):\n",
    "    #    shutil.rmtree(destination_dir)\n",
    "\n",
    "    training_dir = destination_dir + 'training_224/'\n",
    "    validation_dir = destination_dir + 'validation_224/'\n",
    "    test_dir = destination_dir + 'test_224/'\n",
    "    os.makedirs(training_dir)\n",
    "    os.makedirs(validation_dir)\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "    labels = pd.read_csv( source_dir + 'all.csv')\n",
    "    print labels.head()\n",
    "    validation_dict = {}\n",
    "    test_dict = {}\n",
    "\n",
    "    for c in validation_categories:\n",
    "        validation_dict[c] = []\n",
    "\n",
    "    for c in test_categories:\n",
    "        test_dict[c] = []\n",
    "\n",
    "\n",
    "    # test set creation\n",
    "    test_set = []\n",
    "\n",
    "    for i, rows in labels.iterrows():\n",
    "        if test_dict.has_key(rows['label']):\n",
    "            test_dict[rows['label']].append(rows['image'])\n",
    "\n",
    "    for k in test_dict:\n",
    "        np.random.seed(0)\n",
    "        n = math.ceil(test_percentage * len(test_dict[k]) / 100.0)\n",
    "        random_array = np.random.choice(test_dict[k],int(n))\n",
    "        test_set = test_set + random_array.tolist()\n",
    "\n",
    "\n",
    "    #validation set creation\n",
    "    validation_set = []\n",
    "\n",
    "    for i, rows in labels.iterrows():\n",
    "        if rows['image'] not in test_set:\n",
    "            if validation_dict.has_key(rows['label']):\n",
    "                validation_dict[rows['label']].append(rows['image'])\n",
    "\n",
    "    for l in validation_dict:\n",
    "        np.random.seed(0)\n",
    "        n = math.ceil(validation_percentage * len(validation_dict[l]) / 100.0)\n",
    "        random_array = np.random.choice(validation_dict[l],int(n))\n",
    "        validation_set = validation_set + random_array.tolist()\n",
    "\n",
    "    training_images = []\n",
    "    training_labels = []\n",
    "    validation_images = []\n",
    "    validation_labels =[]\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "\n",
    "    for i, rows in labels.iterrows():\n",
    "        new_name = rows['image']\n",
    "        new_label = rows['label']\n",
    "\n",
    "        if rows['image'] in test_set:\n",
    "            test_images.append(new_name)\n",
    "            test_labels.append(new_label)\n",
    "            process_and_save_image(sourceDir + 'data/' + rows['image'] + \".jpg\", test_dir + new_name + \".tiff\");\n",
    "        elif rows['image'] in validation_set:\n",
    "            validation_images.append(new_name)\n",
    "            validation_labels.append(new_label)\n",
    "            process_and_save_image(sourceDir + 'data/' + rows['image'] + \".jpg\", validation_dir + new_name + \".tiff\")\n",
    "        else:\n",
    "            training_images.append(new_name)\n",
    "            training_labels.append(new_label)\n",
    "            process_and_save_image(sourceDir + 'data/' + rows['image'] + \".jpg\", training_dir + new_name + \".tiff\")\n",
    "\n",
    "    header = ['image', 'label']\n",
    "\n",
    "    # saving training csv\n",
    "    training_out = np.column_stack((training_images, training_labels))\n",
    "    training_out = np.row_stack((header, training_out))\n",
    "    np.savetxt(destination_dir + 'training_labels.csv', training_out, delimiter=',', fmt='%s')\n",
    "\n",
    "    # saving validation csv\n",
    "    validation_out = np.column_stack((validation_images, validation_labels))\n",
    "    validation_out = np.row_stack((header, validation_out))\n",
    "    np.savetxt(destination_dir + 'validation_labels.csv', validation_out, delimiter=',', fmt='%s')\n",
    "\n",
    "    # saving testing csv\n",
    "    test_out = np.column_stack((test_images, test_labels))\n",
    "    test_out = np.row_stack((header, test_out))\n",
    "    np.savetxt(destination_dir + 'test_labels.csv', test_out, delimiter=',', fmt='%s')\n",
    "\n",
    "def process_and_save_image(source_path,destination_path):\n",
    "    img = resize(source_path, 224)\n",
    "    img.save(destination_path, quality=100)\n",
    "\n",
    "def resize(fname, target_size):\n",
    "    # print('Processing image: %s' % fname)\n",
    "    img = Image.open(fname)\n",
    "    return img\n",
    "\n",
    "#calling method\n",
    "create_tefla_data(sourceDir,destDir,categories_picked_for_validation_data,categories_picked_for_test_data,validation_data_percentage,test_data_percentage)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
